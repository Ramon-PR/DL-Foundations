{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191aeb56",
   "metadata": {},
   "source": [
    "# Create a Pytorch Dataset for RIR predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00650649",
   "metadata": {},
   "source": [
    "Tengo 100 ids, del 0 al 99.\n",
    "los microfonos 1, 7 y 34 forman el grupo de micros de referencia\n",
    "y el resto los quiero usar como targets en un dataset de pytorch.\n",
    "En un pase forward, cogería la posicion de uno de los microfonos del grupo target, y los micros del grupo de referencia para predecir la señal en en micro target.\n",
    "Cómo haría el Dataset? Es recomendable usar \"yield\"?\n",
    "ChatGPT Plus\n",
    "\n",
    "Tu planteamiento para crear un dataset personalizado en PyTorch tiene mucho sentido, y no, normalmente no se recomienda usar yield dentro de un Dataset de PyTorch porque:\n",
    "\n",
    "    PyTorch espera que el __getitem__ devuelva datos directamente (no un generador).\n",
    "\n",
    "    El sistema de DataLoader usa indexación aleatoria y múltiples workers, y yield no es compatible con eso directamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377ce55",
   "metadata": {},
   "source": [
    "## Dataset that returns positions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e18c1fc",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a6e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from exp.nb_rirDatasets import MeshRIR\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fceb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3969"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "ds = MeshRIR(root=\"data\", download=False, dataset=\"S1\", \n",
    "            source_id=0, start_signal=0, signal_size=512)\n",
    "\n",
    "ds.get_nmics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "763013c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of All mics: 3969\n",
      "Length of prediction mics: 3964\n"
     ]
    }
   ],
   "source": [
    "# ids of microphones used for the interpolation\n",
    "ids_env = [7, 100, 1002, 2958, 2643]\n",
    "\n",
    "# ids of microphones used for the prediction\n",
    "ids_pred_mics = [i for i in range(ds.get_nmics()) if i not in ids_env]\n",
    "\n",
    "print(f\"Length of All mics: {ds.get_nmics()}\")\n",
    "print(f\"Length of prediction mics: {len(ids_pred_mics)}\")\n",
    "\n",
    "env = {}\n",
    "env['signal'] = [ds.get_mic(i) for i in ids_env]\n",
    "env['time'] = [ds.get_time(i) for i in ids_env]\n",
    "env['position'] = [ds.get_pos(i) for i in ids_env]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca27d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "env['signal'] = torch.from_numpy(np.stack(env['signal']).astype(np.float32))\n",
    "env['time'] = torch.from_numpy(np.stack(env['time']).astype(np.float32))\n",
    "env['position'] = torch.from_numpy(np.stack(env['position']).astype(np.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c3323ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 512])\n",
      "torch.Size([5, 512])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(env['signal'].shape)\n",
    "print(env['time'].shape)\n",
    "print(env['position'].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a302225b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n",
      "(512,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "idx = 4\n",
    "target = dict(signal=ds.get_mic(idx), \n",
    "             time=ds.get_time(idx), \n",
    "             position=ds.get_pos(idx))\n",
    "print(target['signal'].shape)\n",
    "print(target['time'].shape)\n",
    "print(target['position'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d853549",
   "metadata": {},
   "source": [
    "### Dataset Class with a constant environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d3d5279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from exp.nb_rirDatasets import DB_microphones\n",
    "from typing import List\n",
    "\n",
    "class DSRirFixedEnv(Dataset):\n",
    "    \"\"\" \n",
    "    Dataset with a fixed environment\n",
    "    In this version I let the the predict microphone to be any of the micros in the data\n",
    "    (including those labeled as environment)\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 mic_dataset: DB_microphones, \n",
    "                 ids_env: List[int],\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.dataset = mic_dataset\n",
    "        self.ids_env = ids_env        \n",
    "\n",
    "        # Environment microphones\n",
    "        self.env = {}\n",
    "        self.env['signal'] = [ds.get_mic(i) for i in ids_env]\n",
    "        self.env['time'] = [ds.get_time(i) for i in ids_env]\n",
    "        self.env['position'] = [ds.get_pos(i) for i in ids_env]\n",
    "        # Change to torch tensors\n",
    "        self.env['signal'] = torch.from_numpy(np.stack(self.env['signal']).astype(np.float32))\n",
    "        self.env['time'] = torch.from_numpy(np.stack(self.env['time']).astype(np.float32))\n",
    "        self.env['position'] = torch.from_numpy(np.stack(self.env['position']).astype(np.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.get_nmics()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        In this version the environment is fixed, so in the __getitem__ \n",
    "        we only return the target \n",
    "        \"\"\"       \n",
    "        \n",
    "        return dict(signal=self.dataset.get_mic(idx),\n",
    "                    time=self.dataset.get_time(idx), \n",
    "                    position=self.dataset.get_pos(idx))\n",
    " \n",
    "    def get_env(self):\n",
    "        \"\"\"\n",
    "        Return the environment\n",
    "        \"\"\"\n",
    "        return self.env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b564d5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 3969\n",
      "Target at index 1. \n",
      "using list indexing:   [-0.45 -0.5  -0.2 ] \n",
      "and using __getitem__: [-0.45 -0.5  -0.2 ] \n",
      "\n",
      "Environment \n",
      "Positions:\n",
      "tensor([[ 0.3000, -0.3000, -0.2000],\n",
      "        [-0.2000,  0.2000, -0.2000],\n",
      "        [ 0.3500, -0.4000, -0.1500]])\n"
     ]
    }
   ],
   "source": [
    "dsrir = DSRirFixedEnv(ds, ids_env=[100, 300, 500])\n",
    "\n",
    "# Accesing an element\n",
    "print(f\"Length of dataset: {len(dsrir)}\")\n",
    "print(\"Target at index 1. \")\n",
    "print(f\"using list indexing:   {dsrir[1]['position']} \") \n",
    "print(f\"and using __getitem__: {dsrir.__getitem__(1)['position']} \")\n",
    "\n",
    "# Print the environment\n",
    "print()\n",
    "print(\"Environment \\nPositions:\")\n",
    "print(dsrir.get_env()['position'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e3291",
   "metadata": {},
   "source": [
    "### Datasets with random environments in each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4901ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import math \n",
    "import random\n",
    "        \n",
    "class DS_random_pick(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mic_dataset: DB_microphones, \n",
    "        n_ref_mics: int = 4,  # number of mics I will pick as my environment to interpolate\n",
    "        max_combinations: int = 1000,  # number of maximum combinations\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dataset = mic_dataset\n",
    "        self.n_ref_mics = n_ref_mics\n",
    "        self.max_combinations = max_combinations\n",
    "\n",
    "        # number of combinations without replacement of n elements in groups of r : n!/(r!*(n-r)!)\n",
    "        n = self.dataset.get_nmics()\n",
    "        r = self.n_ref_mics\n",
    "        n_comb = int(math.factorial(n) / math.factorial(n - r) / math.factorial(r))\n",
    "        self.len_comb_dataset = min(n_comb, self.max_combinations)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_comb_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ids = random.sample(range(self.dataset.get_nmics()), self.n_ref_mics + 1)\n",
    "\n",
    "        signals = [self.dataset.get_mic(i) for i in ids]\n",
    "        positions = [self.dataset.get_pos(i) for i in ids]\n",
    "        times = [self.dataset.get_time(i) for i in ids]\n",
    "\n",
    "        env = dict(\n",
    "             signal=torch.from_numpy(np.stack(signals[1:]).astype(np.float32)),\n",
    "             time=torch.from_numpy(np.stack(times[1:]).astype(np.float32)),\n",
    "             position=torch.from_numpy(np.stack(positions[1:]).astype(np.float32)),\n",
    "             )\n",
    "        \n",
    "        target = dict(\n",
    "             signal=torch.from_numpy(np.stack(signals[0]).astype(np.float32)),\n",
    "             time=torch.from_numpy(np.stack(times[0]).astype(np.float32)),\n",
    "             position=torch.from_numpy(np.stack(positions[0]).astype(np.float32)),\n",
    "             )\n",
    "                   \n",
    "        return env, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d42dfe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrir2 = DS_random_pick(mic_dataset=ds, n_ref_mics=4, max_combinations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "502bbc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2000, -0.3500,  0.1500],\n",
      "        [ 0.1500, -0.5000,  0.2000],\n",
      "        [-0.2500,  0.1500,  0.2000],\n",
      "        [ 0.1500, -0.4500, -0.1000]])\n",
      "tensor([ 0.2000, -0.3500,  0.2000])\n"
     ]
    }
   ],
   "source": [
    "type(dsrir2[0])\n",
    "env2, target2 = dsrir2[0]\n",
    "print(env2['position'])\n",
    "print(target2['position'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286ea9e",
   "metadata": {},
   "source": [
    "### Datamodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "066a988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import lightning.pytorch as L\n",
    "from torch.utils.data import random_split, ConcatDataset, DataLoader\n",
    "from typing import List\n",
    "\n",
    "def ensure_list(x):\n",
    "    if isinstance(x, Dataset):\n",
    "        return [x]\n",
    "    elif isinstance(x, list):\n",
    "        return x\n",
    "    elif x is None:\n",
    "        return []\n",
    "    else:\n",
    "        raise TypeError(f\"Expected Dataset or list of Datasets, got {type(x)}\")\n",
    "    \n",
    "class DM_PL_DataModule(L.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 ls_datasets_train: List[torch.utils.data.Dataset] = [], \n",
    "                 ls_datasets_test: List[torch.utils.data.Dataset] = [],\n",
    "                 batch_size: int = 64, num_workers: int = 0, \n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.ls_datasets_train = ensure_list(ls_datasets_train) \n",
    "        self.ls_datasets_test = ensure_list(ls_datasets_train)\n",
    "\n",
    "    def setup(self, stage):\n",
    "        if stage == \"fit\":\n",
    "            self.ds_train, self.ds_val = random_split( ConcatDataset(self.ls_datasets_train), \n",
    "                                                        [0.8, 0.2])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\":\n",
    "            self.ds_test = ConcatDataset(self.ls_datasets_test)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds_train, batch_size=self.batch_size, shuffle=True,\n",
    "            num_workers=self.num_workers, pin_memory=False, collate_fn=None)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds_val, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.ds_test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd85f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsize = 128\n",
    "ds1  = MeshRIR(root=\"data\", download=False, dataset=\"S1\",\n",
    "               source_id=0, start_signal=0, signal_size=nsize)\n",
    "\n",
    "ds2 = MeshRIR(root=\"data\", download=False, dataset=\"S32\",\n",
    "              source_id=3, start_signal=0, signal_size=nsize)\n",
    "\n",
    "dsrir1 = DSRirFixedEnv(ds1, ids_env=[100, 300, 500, 1000])\n",
    "dsrir2 = DSRirFixedEnv(ds2, ids_env=[101, 301, 501, 1001])\n",
    "\n",
    "dsrir3 = DS_random_pick(ds1, n_ref_mics=4, max_combinations=1000)\n",
    "dsrir4 = DS_random_pick(ds2, n_ref_mics=4, max_combinations=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2e2d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DM_PL_DataModule( dsrir1, [], batch_size=12, num_workers=0)\n",
    "CD = ConcatDataset(dm.ls_datasets_train) # error\n",
    "\n",
    "# CD = ConcatDataset(dsrir1) # error\n",
    "# CD = ConcatDataset([dsrir1]) # Ok\n",
    "# Si aplicas list() a algo que no es iterable, como un int o un objeto que no define __iter__, obtendrás un error:\n",
    "# list(123)  # ❌ TypeError: 'int' object is not iterable\n",
    "# ds = MyDataset()\n",
    "# list(ds)  # devuelve una lista de samples si MyDataset es iterable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c817027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1 = DM_PL_DataModule( dsrir1, dsrir2, batch_size=12, num_workers=0)\n",
    "dm2 = DM_PL_DataModule( dsrir3, dsrir4, batch_size=12, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "212b0537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length ds_train: 3176\n",
      "Length ds_train: 800\n"
     ]
    }
   ],
   "source": [
    "for dm in [dm1, dm2]:\n",
    "    dm.setup(stage='fit')\n",
    "    print(f\"Length ds_train: {dm.ds_train.__len__()}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d91c64",
   "metadata": {},
   "source": [
    "I selected 80% for train 20% for validation, so for a dataset of 1000 samples, 800 are in the train dataset and 200 in the validation dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FNOs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
